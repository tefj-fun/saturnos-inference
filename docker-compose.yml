services:
  saturnos-inference:
    container_name: saturnos-inference
    build:
      context: .
      dockerfile: Dockerfile
      network: host
    image: saturnos-inference:latest
    restart: unless-stopped
    runtime: nvidia
    network_mode: host
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    env_file:
      - .env.local
    volumes:
      - ./models:/app/models
      - ./.env.local:/app/.env.local:ro
